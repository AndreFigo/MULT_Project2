{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install librosa\n",
    "# and such, in case it is needed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import librosa\n",
    "import scipy\n",
    "from scipy.signal import stft\n",
    "from scipy.fftpack import fft\n",
    "from scipy.fftpack import dct\n",
    "import matplotlib.pyplot as plt\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050\n",
    "MONO = True\n",
    "NUM_MAT = 9\n",
    "N_SONGS = 900\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(filename:str) -> np.ndarray:\n",
    "    ans = np.genfromtxt(filename, skip_header = 1, delimiter=',')\n",
    "    return ans [:,1:-1] # returns all feture values but the name and the quadrant\n",
    "\n",
    "\n",
    "def export_csv(filename:str,  array:np.ndarray, fmt='%.18e') -> None:\n",
    "    np.savetxt(filename, array, delimiter =',', fmt=fmt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_debug(*args, **kwargs):\n",
    "    if DEBUG:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_features(matrix: np.ndarray) -> np.ndarray:\n",
    "    maxs = np.max(matrix, axis = 0)\n",
    "    mins = np.min(matrix, axis = 0)\n",
    "    ans= np.array(matrix)\n",
    "    ans[np.arange(len(matrix)),:] = (ans[np.arange(len(matrix)),: ] - mins)/(maxs-mins)\n",
    "    return ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_normalized_features() -> np.ndarray:\n",
    "    data = import_csv(\"dataset/top100_features.csv\")\n",
    "    n_data = normalize_features(data)\n",
    "    print_debug(n_data)\n",
    "    # print_debug('shape: ', n_data.shape)\n",
    "    export_csv('dataset/normalized_features.csv', n_data)\n",
    "    return n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex2_1():\n",
    "    save_normalized_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(sample, frame_length=2048,  hop_length=512):\n",
    "\n",
    "    sample_size= len(sample)\n",
    "    n_windows = (sample_size)// hop_length + 1\n",
    "    zrc= np.zeros((1, n_windows))\n",
    "\n",
    "\n",
    "    begs= np.arange(n_windows)*hop_length - frame_length//2\n",
    "    begs[begs<0]=0\n",
    "    ends= np.arange(n_windows)*hop_length + frame_length//2\n",
    "    ends[ends>sample_size]= sample_size\n",
    "    for i in range(n_windows):\n",
    "        \n",
    "        zrc[0,i] = np.sum(np.abs(np.diff(sample[begs[i]:ends[i]] > 0)))/(frame_length)\n",
    "\n",
    "\n",
    "    return zrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(sample, frame_length=2048,  hop_length=512):\n",
    "\n",
    "    sample_size= len(sample)\n",
    "    n_windows = (sample_size)// hop_length + 1\n",
    "    arr= np.zeros((1, n_windows))\n",
    "\n",
    "\n",
    "    begs= np.arange(n_windows)*hop_length - frame_length//2\n",
    "    begs[begs<0]=0\n",
    "    ends= np.arange(n_windows)*hop_length + frame_length//2\n",
    "    ends[ends>sample_size]= sample_size\n",
    "    for i in range(n_windows):\n",
    "        \n",
    "        arr[0,i] =np.sqrt( np.sum(sample[begs[i]:ends[i]]**2)/(frame_length) )\n",
    "\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_rolloff(sample, sr= 22050, frame_length= 2048, hop_length=512):\n",
    "    sample_size= len(sample)\n",
    "    n_windows = (sample_size)// hop_length + 1\n",
    "    arr= np.zeros((1, n_windows))\n",
    "\n",
    "\n",
    "    begs= np.arange(n_windows)*hop_length - frame_length//2\n",
    "    begs[begs<0]=0\n",
    "    ends= np.arange(n_windows)*hop_length + frame_length//2\n",
    "    ends[ends>sample_size]= sample_size\n",
    "\n",
    "\n",
    "    for i in range(n_windows):\n",
    "\n",
    "        x = sample[begs[i]:ends[i]]\n",
    "\n",
    "        X = fft(x * np.hanning(len(x)))\n",
    "\n",
    "        \n",
    "        N = len(x)\n",
    "        B = math.ceil(N/2)\n",
    "        df = sr/N\n",
    "        magnitude = np.abs(X[0:B])\n",
    "        freq_bins = np.arange(B) * df\n",
    "\n",
    "        total_mag = np.sum(magnitude)\n",
    "        threshold = 0.85 * total_mag\n",
    "        mag_per_index = np.cumsum(magnitude)\n",
    "            \n",
    "        aux = mag_per_index > threshold\n",
    "\n",
    "        pos = np.where(aux.any(), aux.argmax(), B-1)\n",
    "\n",
    "\n",
    "        arr[0,i] = freq_bins[pos]\n",
    "\n",
    "    return arr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_centroid(sample, sr= 22050, frame_length= 2048, hop_length=512):\n",
    "\n",
    "    sample_size= len(sample)\n",
    "    n_windows = (sample_size)// hop_length + 1\n",
    "    arr= np.zeros((1, n_windows))\n",
    "\n",
    "\n",
    "    begs= np.arange(n_windows)*hop_length - frame_length//2\n",
    "    begs[begs<0]=0\n",
    "    ends= np.arange(n_windows)*hop_length + frame_length//2\n",
    "    ends[ends>sample_size]= sample_size\n",
    "\n",
    "\n",
    "    for i in range(n_windows):\n",
    "\n",
    "        x = sample[begs[i]:ends[i]]\n",
    "\n",
    "        X = fft(x * np.hanning(len(x)))\n",
    "\n",
    "        \n",
    "        N = len(x)\n",
    "        B = math.ceil(N/2)\n",
    "        df = sr/N\n",
    "\n",
    "        magnitude = np.abs(X[0:B])\n",
    "        freq_bins = np.arange(B) * df\n",
    "\n",
    "        arr[0,i] = np.sum(magnitude * freq_bins)/ np.sum(magnitude)\n",
    "\n",
    "    return arr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_bandwidth(sample, sr= 22050, frame_length= 2048, hop_length=512, p=2):\n",
    "    \n",
    "    sample_size= len(sample)\n",
    "    n_windows = (sample_size)// hop_length + 1\n",
    "    arr= np.zeros((1, n_windows))\n",
    "\n",
    "\n",
    "    begs= np.arange(n_windows)*hop_length - frame_length//2\n",
    "    begs[begs<0]=0\n",
    "    ends= np.arange(n_windows)*hop_length + frame_length//2\n",
    "    ends[ends>sample_size]= sample_size\n",
    "\n",
    "    for i in range(n_windows):\n",
    "\n",
    "        x = sample[begs[i]:ends[i]]\n",
    "\n",
    "        X = fft(x * np.hanning(len(x)))\n",
    "\n",
    "        \n",
    "        N = len(x)\n",
    "        B = math.ceil(N/2)\n",
    "        df = sr/N\n",
    "\n",
    "        magnitude = np.abs(X[0:B])\n",
    "        freq_bins = np.arange(B) * df\n",
    "        centroid = np.sum(magnitude * freq_bins)/ np.sum(magnitude)\n",
    "\n",
    "\n",
    "        # ! normalization is wrong\n",
    "        arr[0,i] =  np.sum(magnitude*(freq_bins-centroid)**p)**(1.0/p)\n",
    "\n",
    "\n",
    "    return arr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_flatness(sample, sr= 22050, frame_length= 2048, hop_length=512, safe_value=1e-10):\n",
    "    \n",
    "    sample_size= len(sample)\n",
    "    n_windows = (sample_size)// hop_length + 1\n",
    "    arr= np.zeros((1, n_windows))\n",
    "\n",
    "\n",
    "    begs= np.arange(n_windows)*hop_length - frame_length//2\n",
    "    begs[begs<0]=0\n",
    "    ends= np.arange(n_windows)*hop_length + frame_length//2\n",
    "    ends[ends>sample_size]= sample_size\n",
    "\n",
    "    for i in range(n_windows):\n",
    "\n",
    "        x = sample[begs[i]:ends[i]]\n",
    "\n",
    "        X = fft(x * np.hanning(len(x)))\n",
    "\n",
    "        \n",
    "        N = len(x)\n",
    "        B = math.ceil(N/2)\n",
    "        df = sr/N\n",
    "\n",
    "        magnitude = np.abs(X[0:B])\n",
    "        \n",
    "        magnitude= (magnitude+safe_value) **2\n",
    "        # magnitude = np.maximum(safe_value, np.abs(X[0:B]) ** 2)\n",
    "        # arr[0,i] =  (np.prod(magnitude+safe_value)**(1.0/B))/ \n",
    "\n",
    "        arr[0,i] = np.exp(np.sum(np.log(magnitude  ))/ B ) / ((np.sum(magnitude)/B)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return arr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hertz_to_mel(hertz:float)-> float:\n",
    "    return 2595 * np.log10(1+hertz/700)\n",
    "\n",
    "def mel_to_hertz(mel:float) -> float:\n",
    "    return 700 * (np.power(10, mel/2595)-1)\n",
    "# now for the implementation of MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(sample: np.ndarray, sr:int, n_mfccs:int=13, frame_length= 2048, hop_length=512):\n",
    "    sample_size= len(sample)\n",
    "    n_windows = (sample_size)// hop_length + 1\n",
    "    begs= np.arange(n_windows)*hop_length - frame_length//2\n",
    "    begs[begs<0]=0\n",
    "    ends= np.arange(n_windows)*hop_length + frame_length//2\n",
    "    ends[ends>sample_size]= sample_size\n",
    "\n",
    "    delta_f = sr / frame_length\n",
    "    arr_mfccs = []\n",
    "    f_max: float = sr/2\n",
    "    mel_max: float = hertz_to_mel(f_max)\n",
    "    window_centers = (np.arange(1,41)/41) * mel_max\n",
    "    window_centers = mel_to_hertz(window_centers)\n",
    "\n",
    "    # ! meter n_windows\n",
    "    for i in range(n_windows):\n",
    "        sample_to_dft: np.ndarray = sample[begs[i]:ends[i]] * np.hanning(ends[i]-begs[i])\n",
    "        dft_sample = fft(sample_to_dft)\n",
    "        dft_magnitude = np.abs(dft_sample)[:len(dft_sample)//2+1] # dft coefficients from 0 to 1024 * delta_f\n",
    "        log_fccs = []\n",
    "        for j in range(40):\n",
    "            inf_freq:float = 0\n",
    "            sup_freq:float = f_max\n",
    "            mid_freq = window_centers[j]\n",
    "            if j!=0:\n",
    "                inf_freq = window_centers[j-1]\n",
    "            if j<39:     \n",
    "                sup_freq = window_centers[j+1]\n",
    "            if delta_f == 0:\n",
    "                print(\"lol\")\n",
    "            pos_inf_freq = int(np.ceil(inf_freq / delta_f))\n",
    "            pos_sup_freq = int(np.floor(sup_freq / delta_f))\n",
    "            total_cc = 0\n",
    "            for k in range(pos_inf_freq, min(len(dft_magnitude),pos_sup_freq+1)):\n",
    "                freq_k = k*delta_f\n",
    "                coef:float = 0\n",
    "                if freq_k < mid_freq:\n",
    "                    if mid_freq - inf_freq ==0:\n",
    "                        print(\"lol\")\n",
    "                    perc = (freq_k -inf_freq)/(mid_freq-inf_freq)\n",
    "                    coef = perc\n",
    "                else:\n",
    "                    if sup_freq - mid_freq ==0:\n",
    "                        print(\"lol\")\n",
    "                    perc = (freq_k - mid_freq)/(sup_freq-mid_freq)\n",
    "                    coef = 1-perc\n",
    "                total_cc += coef * dft_magnitude[k]\n",
    "            log_total_cc = np.log10(total_cc)\n",
    "            if np.isnan(log_total_cc) or np.isinf(log_total_cc):\n",
    "                log_total_cc=0\n",
    "            log_fccs.append(log_total_cc)\n",
    "        log_fccs = np.array(log_fccs)\n",
    "        dft_coefs = dct(log_fccs)[:n_mfccs]\n",
    "        arr_mfccs.append(dft_coefs)\n",
    "    ret = np.array(arr_mfccs).T\n",
    "    # print(\"ret shape: \",ret.shape)\n",
    "    # 961413169\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname ='dataset/allSongs'\n",
    "filename = 'MT0000202045.mp3'\n",
    "y,fs = librosa.load(dirname+'/'+filename, sr = SR, mono = MONO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1295)\n",
      "[[0.10003239 0.05057845 0.0463913  ... 0.01123334 0.01457003 0.02427914]]\n",
      "(1, 1295)\n",
      "[[0.09080229 0.05019897 0.04687352 ... 0.01134397 0.0139296  0.01996238]]\n",
      "\n",
      "0.9999843341008465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rms1  = librosa.feature.spectral_flatness(y)\n",
    "print(rms1.shape)\n",
    "print(rms1)\n",
    "rms2 = spectral_flatness(y)\n",
    "print(rms2.shape)\n",
    "print(rms2)\n",
    "print()\n",
    "arr_coef = []\n",
    "for i in range(len(rms1)):\n",
    "    arr_coef.append(np.corrcoef(rms1[i], rms2[i]))\n",
    "\n",
    "# print(arr_coef)\n",
    "print(np.average(arr_coef))\n",
    "# print(calculate_stats(rms1))\n",
    "# print(calculate_stats(rms2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(rms1.tolist())\n",
    "# print(rms2.tolist())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1622776601683795"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= np.arange(3)\n",
    "aux = np.cumsum(x)>3\n",
    "aux = 10\n",
    "aux**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(array:np.ndarray):\n",
    "    mean= np.mean(array)\n",
    "    std =  np.std(array)\n",
    "    skewness = scipy.stats.skew(array)\n",
    "    kurtosis = scipy.stats.kurtosis(array)\n",
    "    median = np.median(array)\n",
    "    maximum = np.max(array)\n",
    "    minimum = np.min(array)\n",
    "\n",
    "    return np.array([mean,std,skewness, kurtosis,median, maximum, minimum])\n",
    "\n",
    "\n",
    "def features_librosa(dirname:str) -> np.ndarray:    \n",
    "    ans=np.array([])\n",
    "    i=0\n",
    "    for filename in os.listdir(dirname):\n",
    "        print_debug(filename)\n",
    "        i+=1\n",
    "        # spectral features\n",
    "        y,fs = librosa.load(dirname+'/'+filename, sr = SR, mono = MONO)\n",
    "        mfccs = librosa.feature.mfcc(y, sr=SR, n_mfcc=13)\n",
    "        spcentroid = librosa.feature.spectral_centroid(y, sr=SR)\n",
    "        spband = librosa.feature.spectral_bandwidth(y, sr=SR)\n",
    "        spcontrast = librosa.feature.spectral_contrast(y, sr=SR)\n",
    "        spflatness = librosa.feature.spectral_flatness(y)\n",
    "        sprolloff = librosa.feature.spectral_rolloff(y, sr=SR)\n",
    "        rms = librosa.feature.rms(y)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        f0 = librosa.yin(y, sr=SR, fmin=20, fmax=11025)\n",
    "        f0[f0==11025]=0\n",
    "        all_features_array = np.vstack((mfccs, spcentroid, spband, spcontrast, spflatness, sprolloff, f0, rms, zcr))\n",
    "        all_stats = np.apply_along_axis(calculate_stats, 1, all_features_array).flatten()\n",
    "\n",
    "\n",
    "        tempo = librosa.beat.tempo(y,sr=SR)\n",
    "        aid = np.append(all_stats, tempo)\n",
    "        # print_debug(aid)\n",
    "        if i==1:\n",
    "            ans = np.array(aid)\n",
    "        else:\n",
    "            ans= np.vstack((ans,aid))\n",
    "    # print_debug(\"ans: \",ans)\n",
    "    # print_debug(\"ans shape: \",ans.shape)\n",
    "    ans = np.array(ans)\n",
    "    return normalize_features(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3\n",
    "\n",
    "def features_by_hand(dirname:str) -> np.ndarray:    \n",
    "    ans=np.array([])\n",
    "    i=0\n",
    "    for filename in os.listdir(dirname):\n",
    "        print_debug(filename)\n",
    "        i+=1\n",
    "        # spectral features\n",
    "        print(i)\n",
    "        y,fs = librosa.load(dirname+'/'+filename, sr = SR, mono = MONO)\n",
    "        mfccs = mfcc(y, sr=SR, n_mfccs=13)\n",
    "        spcentroid = spectral_centroid(y, sr=SR)\n",
    "        spband = spectral_bandwidth(y, sr=SR)\n",
    "        spcontrast = librosa.feature.spectral_contrast(y, sr=SR)\n",
    "        spflatness = spectral_flatness(y)\n",
    "        sprolloff = spectral_rolloff(y, sr=SR)\n",
    "        rms_arr = rms(y)\n",
    "        zcr_arr = zcr(y)\n",
    "        f0 = librosa.yin(y, sr=SR, fmin=20, fmax=11025)\n",
    "        f0[f0==11025]=0\n",
    "        all_features_array = np.vstack((mfccs, spcentroid, spband, spcontrast, spflatness, sprolloff, f0, rms_arr, zcr_arr))\n",
    "        all_stats = np.apply_along_axis(calculate_stats, 1, all_features_array).flatten()\n",
    "\n",
    "\n",
    "        tempo = librosa.beat.tempo(y,sr=SR)\n",
    "        aid = np.append(all_stats, tempo)\n",
    "        # print_debug(aid)\n",
    "        if i==1:\n",
    "            ans = np.array(aid)\n",
    "        else:\n",
    "            ans= np.vstack((ans,aid))\n",
    "    # print_debug(\"ans: \",ans)\n",
    "    # print_debug(\"ans shape: \",ans.shape)\n",
    "    ans = np.array(ans)\n",
    "    return normalize_features(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex2_2():\n",
    "    features_norm_obtained = features_librosa('dataset/allSongs')\n",
    "    export_csv('dataset/song_features.csv', features_norm_obtained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex2_3():\n",
    "    features_norm_obtained = features_by_hand('dataset/allSongs')\n",
    "    export_csv('dataset/song_features_by_hand.csv', features_norm_obtained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex2_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance (vec1:np.ndarray, vec2:np.ndarray) -> float:\n",
    "    return np.linalg.norm(vec1-vec2)\n",
    "\n",
    "def manhattan_distance(vec1:np.ndarray, vec2:np.ndarray) -> float:\n",
    "    return np.sum(np.abs(vec1-vec2))\n",
    "\n",
    "def cosine_distance (vec1:np.ndarray, vec2:np.ndarray) -> float:\n",
    "    return 1 - np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(feature_matrix:np.ndarray, distance_function, filename:str):\n",
    "    lines= len(feature_matrix)\n",
    "    distance_mat =  np.zeros((lines,lines))\n",
    "\n",
    "    # distance_mat[np.arange(lines), np.arange(lines)] = distance_function(feature_matrix[np.arange(lines)], feature_matrix[np.arange(lines)])  \n",
    "    feature_matrix[feature_matrix!=feature_matrix] = 0\n",
    "    \n",
    "    for i in range(len(feature_matrix)):\n",
    "        for j in range(i):\n",
    "            distance_mat[i,j] = distance_function(feature_matrix[i], feature_matrix[j])\n",
    "            distance_mat[j,i] = distance_mat[i,j]\n",
    "\n",
    "    print(filename)\n",
    "    export_csv(filename, distance_mat)\n",
    "    return distance_mat\n",
    "\n",
    "def get_distance_matrices():\n",
    "\n",
    "\n",
    "    song_features = np.genfromtxt('dataset/song_features.csv', skip_header = 0, delimiter=',') \n",
    "    song_features_by_hand = np.genfromtxt('dataset/song_features_by_hand.csv', skip_header = 0, delimiter=',') \n",
    "    # the skip header must be set to zero!!!\n",
    "    top100 = np.genfromtxt('dataset/normalized_features.csv', skip_header = 0, delimiter=',')\n",
    "    d_functions = [euclidean_distance, manhattan_distance, cosine_distance]\n",
    "    function_names=['euclidean','manhattan', 'cosine']\n",
    "    matrices = [ song_features,top100, song_features_by_hand]\n",
    "    matrix_names=['song_features','top100', 'by_hand']\n",
    "    n_functions= len(d_functions)\n",
    "    n_mat = len(matrices)\n",
    "    n_songs=  len(song_features)\n",
    "    arr = np.zeros(( n_functions* n_mat,n_songs,n_songs ))\n",
    "    # arr = [[[] for i in range(len(function_names))] for j in range(len(matrix_names))]\n",
    "    \n",
    "    for i in range(len(function_names)):\n",
    "        for j in range(len(matrices)):\n",
    "            filename = f\"dataset/results/{function_names[i]}_{matrix_names[j]}.csv\"\n",
    "            if not os.path.exists(filename):\n",
    "                arr[i*n_mat+j]= distance_matrix(matrices[j], d_functions[i],filename)\n",
    "    # arr = np.array(arr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_distance_mats()->np.ndarray:\n",
    "\n",
    "    arr = np.zeros((NUM_MAT, N_SONGS, N_SONGS ))\n",
    "\n",
    "    filenames = ['euclidean_song_features','euclidean_top100','euclidean_by_hand','manhattan_song_features','manhattan_top100', 'manhattan_by_hand','cosine_song_features','cosine_top100','cosine_by_hand']\n",
    "\n",
    "    for i in range(len(filenames)):\n",
    "        gen =  np.genfromtxt('dataset/results/'+filenames[i]+'.csv', skip_header = 0, delimiter=',')\n",
    "        arr[i] = gen\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_ranking(filename, index, distance_matrices, all_songs)-> np.ndarray:\n",
    "    print_debug( \"Music: \", filename)\n",
    "    ans = []\n",
    "    for i in range(len(distance_matrices)):\n",
    "        line=distance_matrices[i,index]\n",
    "        sorted_distances = np.argsort(line)\n",
    "        indices = sorted_distances[1:21]\n",
    "        ans.append(indices)\n",
    "        if DEBUG:\n",
    "            print_debug(\"According to metric \",i)\n",
    "            for j in indices:\n",
    "                print_debug(all_songs[j])\n",
    "            print_debug(\"------\")\n",
    "    ans = np.array(ans)\n",
    "    return ans\n",
    "\n",
    "def get_rankings(distance_matrices, all_songs, queries)->np.ndarray:\n",
    "    rks=[]\n",
    "    for q in queries:\n",
    "        index = all_songs.index(q)\n",
    "        rks.append(get_query_ranking ( q,index, distance_matrices, all_songs))\n",
    "    rks = np.array(rks)\n",
    "    a,b,c = rks.shape\n",
    "    ans = np.zeros((b,a,c))\n",
    "    for i in range(b):\n",
    "        ans[i] = rks[:,i,:]\n",
    "    return ans \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_distance(md1:np.ndarray, md2:np.ndarray)->int:\n",
    "    ans=0\n",
    "    # 1, 3,9,11\n",
    "    inds = [1,3]\n",
    "    sps = [9,11]\n",
    "    for i in inds:\n",
    "        if md1[i] == md2[i]:\n",
    "            ans +=1\n",
    "    # print(ans)\n",
    "    for s in sps:\n",
    "        # print_debug(\"s = \",s, \" and md1[s] = \", md1[s], \" and md2[s] =\",md2[s] )\n",
    "        aux1= md1[s][1:-1]\n",
    "        aux2= md2[s][1:-1]\n",
    "        sp1:list = aux1.split(\"; \")\n",
    "        sp2:list = aux2.split(\"; \")\n",
    "        # print(\"sp1 len is \", len(sp1), \"and len sp2 is\", len(sp2))\n",
    "        for str_prop in sp1:\n",
    "            if str_prop in sp2:\n",
    "                ans +=1\n",
    "        \n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "def get_metadata_ranking(filename:str, index:int, all_songs:list, metadata_matrix:np.ndarray)->np.ndarray:\n",
    "    # index of the song\n",
    "    print_debug(\"Music: \", filename)\n",
    "    md_file = metadata_matrix[index]\n",
    "    rating = np.zeros((len(all_songs)))\n",
    "    for i in range(len(all_songs)):\n",
    "        md_i = metadata_matrix[i]\n",
    "        rating[i] = score_distance(md_i, md_file)\n",
    "        print_debug(\"Score: \",rating[i])\n",
    "    rating[index]=-1\n",
    "    sorted_dists = np.argsort(rating)\n",
    "    sorted_dists = np.flip(sorted_dists)\n",
    "    reccoms = sorted_dists[0:20] # the first 20 songs that are supposed to be considered for the ranking\n",
    "    # print(rating[sorted_dists])\n",
    "    return reccoms\n",
    "\n",
    "def get_all_metadata_rankings(all_songs: list, metadata_matrix: np.ndarray, queries:list)->np.ndarray:\n",
    "    a:list =[]\n",
    "    for q in queries:\n",
    "        index:int  = all_songs.index(q)\n",
    "        a.append(get_metadata_ranking(q,index, all_songs, metadata_matrix))\n",
    "    a = np.array(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rankings_matrices(ranking_matrix:np.ndarray, all_songs:list, queries:list) -> None :\n",
    "    for mat in ranking_matrix:\n",
    "        print_rankings(mat, all_songs, queries)\n",
    "\n",
    "\n",
    "def print_rankings(ranking_matrix:np.ndarray, all_songs:list, queries:list)->None:\n",
    "    for i in range(len(queries)):\n",
    "        q = queries[i]\n",
    "        print(\"Recommendation for music\", q, \":\")\n",
    "        for r in ranking_matrix[i]:\n",
    "            print(all_songs[r])\n",
    "        print(\"--------\")\n",
    "\n",
    "def get_music_from_pos(music_array, all_songs):\n",
    "    return [[all_songs[music_array[i,j]] for j in range(len(music_array[i]))] for i in range(len(music_array))]\n",
    "\n",
    "\n",
    "def save_feature_ranks(all_ranks:np.ndarray, name_array: list, all_songs:list):\n",
    "    for i in range(len(all_ranks)):\n",
    "        export_csv(f\"dataset/results/ranking_features_metric_{name_array[i]}.csv\", get_music_from_pos(all_ranks[i],all_songs), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_rank(metadata_rank, feature_ranks):\n",
    "    ret = np.zeros((len(feature_ranks), len(feature_ranks[0])))\n",
    "    # one number for each type of rating, and for each song\n",
    "    for k in range(len(feature_ranks)):\n",
    "        fr = feature_ranks[k] # rating of type k\n",
    "        for i in range(len(fr)): # for each song in the rating\n",
    "            f = len([None for j in range(len(fr[i])) if fr[i,j] in metadata_rank[i]]) / len(fr[i])\n",
    "            print(\"Precision of rating \", k,\" and song \", i,\" is \", f )\n",
    "            ret[k,i] = f\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/results/euclidean_by_hand.csv\n",
      "dataset/results/manhattan_by_hand.csv\n",
      "dataset/results/cosine_by_hand.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive - Universidade de Coimbra\\UNI\\LEI\\Inforestudante\\3_ano\\2_semestre\\MULT\\MULT_Project2\\tp2.ipynb Cell 36'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000035?line=0'>1</a>\u001b[0m get_distance_matrices()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000035?line=1'>2</a>\u001b[0m distance_matrices \u001b[39m=\u001b[39m read_distance_mats() \u001b[39m# reads distance matrices, already obtained\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000035?line=2'>3</a>\u001b[0m all_songs\u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39mdataset/allSongs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000035?line=3'>4</a>\u001b[0m queries \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39mQueries\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\andre\\OneDrive - Universidade de Coimbra\\UNI\\LEI\\Inforestudante\\3_ano\\2_semestre\\MULT\\MULT_Project2\\tp2.ipynb Cell 30'\u001b[0m in \u001b[0;36mread_distance_mats\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000029?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(filenames)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000029?line=7'>8</a>\u001b[0m     gen \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39mgenfromtxt(\u001b[39m'\u001b[39m\u001b[39mdataset/results/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfilenames[i]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m, skip_header \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000029?line=8'>9</a>\u001b[0m     arr[i] \u001b[39m=\u001b[39m gen\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/OneDrive%20-%20Universidade%20de%20Coimbra/UNI/LEI/Inforestudante/3_ano/2_semestre/MULT/MULT_Project2/tp2.ipynb#ch0000029?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "get_distance_matrices()\n",
    "distance_matrices = read_distance_mats() # reads distance matrices, already obtained\n",
    "all_songs= os.listdir('dataset/allSongs')\n",
    "queries = os.listdir('Queries')\n",
    "distance_names = ['euclidean', 'manhattan', 'cosine']\n",
    "distance_sources = ['calculated', 'top100', 'calculated_by_hand']\n",
    "func_names = ['metadata']+ [a+'_'+b for a in distance_names for b in distance_sources]\n",
    "print(func_names)\n",
    "all_feature_ranks = get_rankings(distance_matrices, all_songs, queries) # this gets all rankings\n",
    "metadata_matrix = np.genfromtxt('dataset/panda_dataset_taffc_metadata.csv', delimiter=',',skip_header = 1, encoding = None, dtype=None)\n",
    "metadata_rankings = get_all_metadata_rankings(all_songs, metadata_matrix, queries) # getting rankings based on metadata\n",
    "metadata_rankings = metadata_rankings[np.newaxis, :,:]\n",
    "all_rankings = np.vstack((metadata_rankings, all_feature_ranks)).astype(np.int32)\n",
    "print_rankings_matrices(all_rankings, all_songs, queries)\n",
    "save_feature_ranks(all_rankings, func_names, all_songs) # the rankings are now saved in the disk\n",
    "cr = comp_rank(all_rankings[0], all_rankings[1:])\n",
    "print(cr.shape)\n",
    "export_csv(\"dataset/results/rating_eval.csv\", cr, '%f')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
